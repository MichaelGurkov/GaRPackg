
```{r load_libraries}

library(tidyverse)

library(GaRPackg)

library(zoo)

library(doParallel)

```

```{r Import_data}

raw_df = import_from_fame_template(
  paste0(Sys.getenv("USERPROFILE"),
         "\\OneDrive - Bank Of Israel\\Data\\BoI\\GaR_Data",
         "\\robustness\\data_GaR_20220904.csv")) %>% 
  rename_all(tolower)

raw_df = raw_df %>% 
  select(-starts_with("staff"), -starts_with("dsge"))

raw_df = raw_df %>% 
  filter(date >= as.yearqtr("2000 Q1") & date <= as.yearqtr("2022 Q2"))

```


```{r set_params}

categories_list = list(
  dom_macro = list(
    required = c("gdp_yoy"),
    optional = c(
      "unemployment_diff",
      "cpi_israel_yoy"
    )),
  dom_fin = list(
    required = c(
      "credit_yoy",
      "house_price_yoy",
      "ta125_close_yoy",
      "boi_rate_diff"
      ),
    optional = c(
      "sovereigh_spread",
      "term_spread",
      "ils_usd_impl_vol",
      "ta_35_impl_vol"
    )),
  ext_macro = list(
    required = c(
      "gdp_us_yoy",
      "gdp_euro_yoy"
      ), 
      optional = c(
        "ind_prod_us_yoy",
        "ind_prod_euro_yoy",
        "oecd_imp"
      )),
  ext_fin = list(
    required = c(
      "rate_euro_diff",
      "rate_us_diff"
      ),
      optional = c(
        "eurostoxx600",
        "sp500",
        "us_term_spread",
        "dxy_yoy",
        "oil_p_yoy",
        "non_energy_p_yoy"
      )
    )
)

```

```{r get_all_combinations_test}


category_params_df =  categories_list%>%
  enframe(name = "category", value = "params") %>%
  mutate(part_comb_df = map2(category, params,
                             function(temp_name, temp_part) {
                               temp_part_df = GaRPackg:::get_partition_combs(partitions_list = temp_part,
                                                                  partition_name = temp_name)
                             }))


feature_select_df = map(
  category_params_df$category,function(temp_cat){
    temp_df = category_params_df %>% 
      filter(category == temp_cat) %>% 
      select(part_comb_df) %>% 
      unnest(cols = c(part_comb_df))
    return(temp_df)
                        }
  ) %>% 
  reduce(full_join, by = character()) %>% 
  unite(col = name,starts_with("name"),sep = "-") %>% 
  mutate(partition = pmap(list(dom_macro,dom_fin,ext_macro,ext_fin),c))

rm(category_params_df)

```


```{r preprocess_df}

args_list = GaRPackg:::extract_preprocess_arguments(categories_list)

transformed_df = raw_df %>% 
  mutate(across(args_list$vars_to_yoy, GaRPackg:::calculate_yoy_changes,
                .names = "{.col}_yoy")) %>% 
  mutate(across(args_list$vars_to_diff, GaRPackg:::calculate_diff,
                .names = "{.col}_diff")) %>% 
  mutate(across(args_list$vars_to_4_ma, GaRPackg:::calculate_four_quarters_ma,
                .names = "{.col}_4_ma"))

```

```{r check_data_span, eval=FALSE}

date_range = feature_select_df %>% 
  select(partition) %>% 
  mutate(date_range = map_chr(partition, function(temp_part){
    
    date_range = transformed_df %>% 
      select(date, all_of(unlist(temp_part, use.names = FALSE))) %>% 
      filter(complete.cases(.)) %>% 
      pull(date) %>% 
      range()
    
    
    
    return(paste0(date_range, collapse = "-"))
    
    
  }))

date_range %>% 
  count(date_range)

```


```{r compare_explicit_and_implicit_forecast, eval=FALSE}

temp_part = feature_select_df$partition[[1]]

temp_names = c("date",unlist(temp_part, use.names = FALSE))
  
temp_df = dplyr::select(transformed_df,all_of(temp_names))
  
temp_df = temp_df[stats::complete.cases(temp_df),]
  
explicit_preprocess = GaRPackg::get_gar_forecast(partitions_list = temp_part,
                                vars_df = temp_df,
                                transform_vars_df = FALSE,
                                target_var_name = "gdp_yoy",
                                horizon_list = c(1,4,8,12),
                                quantile_vec = c(0.1,0.25,0.5,0.75,0.95))


implicit_preprocess = get_gar_forecast(partitions_list = temp_part,
                                vars_df = raw_df,
                                target_var_name = "gdp_yoy",
                                horizon_list = c(1,4,8,12),
                                quantile_vec = c(0.1,0.25,0.5,0.75,0.95))

all.equal(explicit_preprocess, implicit_preprocess)

rm(list = str_subset(ls(),"temp"))

```


```{r run_and_save_forecast}

# start_ind = 10001
# 
# end_ind = 32768

numCores = parallel::detectCores() - 1

cl = parallel::makeCluster(numCores)

doParallel::registerDoParallel(cl)

forecast_results = foreach(i = start_ind:end_ind,
                           .packages = c("zoo")) %dopar% {
  
  temp_part = feature_select_df$partition[[i]]
  
  temp_names = c("date",unlist(temp_part, use.names = FALSE))
  
  temp_df = dplyr::select(transformed_df,all_of(temp_names))
  
  temp_df = temp_df[stats::complete.cases(temp_df),]
  
  temp_forecast = GaRPackg::get_gar_forecast(partitions_list = temp_part,
                                vars_df = temp_df,
                                transform_vars_df = FALSE,
                                target_var_name = "gdp_yoy",
                                horizon_list = c(1,4,8,12),
                                quantile_vec = c(0.1,0.25,0.5,0.75,0.95))
  
  

  
}

parallel::stopCluster(cl)

names(forecast_results) = as.character(start_ind:end_ind)


write_rds(forecast_results, paste0(Sys.getenv("USERPROFILE"),
                                   "\\OneDrive - Bank Of Israel\\Data",
                                   "\\BoI\\GaR_Data\\robustness",
                                   "\\forecast_results","_",
                                   start_ind,"_", end_ind,".rds"))

```


```{r check_forecast, eval=FALSE}

temp_forecast = forecast_results[[3333]]

target_part = feature_select_df$partition[[3333]]

target_forecast = get_gar_forecast(partitions_list = target_part,
                                vars_df = raw_df,
                                target_var_name = "gdp_yoy",
                                horizon_list = c(1,4,8,12),
                                quantile_vec = c(0.1,0.25,0.5,0.75,0.95))

all.equal(temp_forecast, target_forecast)

```

## Import forecast and calculate scores

```{r calculate_scores_and_save}

benchmark_df = get_gar_forecast(partitions_list = NULL,
                                vars_df = raw_df,
                                target_var_name = "gdp_yoy",
                                horizon_list = c(1,4,8,12),
                                quantile_vec = c(0.1,0.25,0.5,0.75,0.95))

actual_df = transformed_df %>% 
  select(date, gdp_yoy)

forecast_results = read_rds(paste0("C:\\Users\\U095",
                                   "\\OneDrive - Bank Of Israel\\Data",
                                   "\\BoI\\GaR_Data",
                                   "\\robustness\\forecast_results.rds"))


scores_df = map_dfr(forecast_results, function(temp_forecast_df){
  
  temp_r2 = quantile_r2_score(forecast_df = temp_forecast_df,
                              actual_df = actual_df,
                              benchmark_df = benchmark_df)
  
  return(temp_r2)
  
  
},
.id = "row")

# write_rds(scores_df, paste0(Sys.getenv("USERPROFILE"),
#                                    "\\OneDrive - Bank Of Israel\\Data",
#                                    "\\BoI\\GaR_Data\\robustness",
#                                    "\\scores_df.rds"))


```


```{r check_r2, eval=FALSE}

par_ind = as.numeric(names(forecast_results)[1])

target_part = feature_select_df$partition[[par_ind]]

target_forecast = get_gar_forecast(partitions_list = target_part,
                                vars_df = raw_df,
                                target_var_name = "gdp_yoy",
                                horizon_list = c(1,4,8,12),
                                quantile_vec = c(0.1,0.25,0.5,0.75,0.95))

target_r2 = quantile_r2_score(forecast_df = target_forecast,
                              actual_df = actual_df,
                              benchmark_df = benchmark_df)

all.equal(scores_df %>% 
  filter(row == par_ind) %>% 
  select(-row),target_r2)


```

## Import scores and find best models


```{r}

scores_df %>% 
  ggplot(aes(x = quantile_r2)) + 
  geom_histogram() + 
  geom_vline(xintercept = 0, color = "blue", linetype = "dashed") + 
  facet_grid(vars(horizon), vars(quantile), scales = "free")

```


```{r find_best_models}

scores_df = read_rds(paste0("C:\\Users\\U095",
                   "\\OneDrive - Bank Of Israel\\Data\\BoI",
                   "\\GaR_Data\\robustness\\scores_df.rds"))

best_thresholds = scores_df %>% 
  group_by(horizon, quantile) %>% 
  summarise(threshold_r2 = quantile(quantile_r2, 0.70), .groups = "drop")


best_models = scores_df %>% 
  left_join(best_thresholds, by = c("horizon","quantile")) %>% 
  filter(quantile_r2 >= threshold_r2) %>% 
  group_by(row) %>% 
  mutate(obs = length(quantile_r2)) %>% 
  ungroup() %>% 
  filter(obs == 20)



```



```{r plot_best_partitions}

best_models %>% 
  select(row) %>% 
  distinct()

feature_select_df$partition[[32370]]


scores_df %>% 
  filter(row == 32370) %>% 
  ggplot(aes(as.character(quantile), quantile_r2)) + 
  geom_col() + 
  facet_wrap(~horizon, scales = "free")

```

