
```{r load_libraries}

library(tidyverse)

library(GaRPackg)

library(zoo)

library(doParallel)

```

```{r Import_data}

raw_df = import_from_fame_template(
  paste0(Sys.getenv("USERPROFILE"),
         "\\OneDrive - Bank Of Israel\\Data\\BoI\\GaR_Data",
         "\\robustness\\data_GaR_20220904.csv")) %>% 
  rename_all(tolower)

raw_df = raw_df %>% 
  select(-starts_with("staff"), -starts_with("dsge"))

raw_df = raw_df %>% 
  filter(date >= as.yearqtr("2000 Q1") & date <= as.yearqtr("2022 Q2"))

```


```{r set_params}

categories_list = list(
  dom_macro = list(
    optional = c("gdp_yoy")),
  dom_fin = list(
    optional = c(
      "credit_yoy",
      "house_price_yoy",
      "ta125_close_yoy",
      "boi_rate_diff"
      )),
  ext_macro = list(
    optional = c(
      "gdp_us_yoy",
      "gdp_euro_yoy"
      )),
  ext_fin = list(
    optional = c(
      "rate_euro_diff",
      "rate_us_diff"
      )
    )
)

```

```{r get_all_combinations_test}


category_params_df =  categories_list%>%
  enframe(name = "category", value = "params") %>%
  mutate(part_comb_df = map2(category, params,
                             function(temp_name, temp_part) {
                               temp_part_df = GaRPackg:::get_partition_combs(partitions_list = temp_part,
                                                                  partition_name = temp_name)
                             }))


feature_select_df = map(
  category_params_df$category,function(temp_cat){
    temp_df = category_params_df %>% 
      filter(category == temp_cat) %>% 
      select(part_comb_df) %>% 
      unnest(cols = c(part_comb_df))
    return(temp_df)
                        }
  ) %>% 
  reduce(full_join, by = character()) %>% 
  unite(col = name,starts_with("name"),sep = "-") %>% 
  mutate(partition = pmap(list(dom_macro,dom_fin,ext_macro,ext_fin),c))

rm(category_params_df)

```


```{r preprocess_df}

args_list = GaRPackg:::extract_preprocess_arguments(categories_list)

transformed_df = raw_df %>% 
  mutate(across(args_list$vars_to_yoy, GaRPackg:::calculate_yoy_changes,
                .names = "{.col}_yoy")) %>% 
  mutate(across(args_list$vars_to_diff, GaRPackg:::calculate_diff,
                .names = "{.col}_diff")) %>% 
  mutate(across(args_list$vars_to_4_ma, GaRPackg:::calculate_four_quarters_ma,
                .names = "{.col}_4_ma"))

```

```{r check_data_span, eval=FALSE}

date_range = feature_select_df %>% 
  select(partition) %>% 
  mutate(date_range = map_chr(partition, function(temp_part){
    
    date_range = transformed_df %>% 
      select(date, all_of(unlist(temp_part, use.names = FALSE))) %>% 
      filter(complete.cases(.)) %>% 
      pull(date) %>% 
      range()
    
    
    
    return(paste0(date_range, collapse = "-"))
    
    
  }))

date_range %>% 
  count(date_range)

```


```{r compare_explicit_and_implicit_forecast, eval=FALSE}

temp_part = feature_select_df$partition[[1]]

temp_names = c("date",unlist(temp_part, use.names = FALSE))
  
temp_df = dplyr::select(transformed_df,all_of(temp_names))
  
temp_df = temp_df[stats::complete.cases(temp_df),]
  
explicit_preprocess = GaRPackg::get_gar_forecast(partitions_list = temp_part,
                                vars_df = temp_df,
                                transform_vars_df = FALSE,
                                target_var_name = "gdp_yoy",
                                horizon_list = c(1,4,8,12),
                                quantile_vec = c(0.1,0.25,0.5,0.75,0.95))


implicit_preprocess = get_gar_forecast(partitions_list = temp_part,
                                vars_df = raw_df,
                                target_var_name = "gdp_yoy",
                                horizon_list = c(1,4,8,12),
                                quantile_vec = c(0.1,0.25,0.5,0.75,0.95))

all.equal(explicit_preprocess, implicit_preprocess)

rm(list = str_subset(ls(),"temp"))

```


```{r run_forecast}

start_ind = 1

end_ind = 511

numCores = parallel::detectCores() - 1

cl = parallel::makeCluster(numCores)

doParallel::registerDoParallel(cl)

forecast_results = foreach(i = start_ind:end_ind,
                           .packages = c("zoo")) %dopar% {
  
  temp_part = feature_select_df$partition[[i]]
  
  temp_names = c("date","gdp_yoy",unlist(temp_part, use.names = FALSE))
  
  temp_df = dplyr::select(transformed_df,all_of(temp_names))
  
  temp_df = temp_df[stats::complete.cases(temp_df),]
  
  temp_forecast = GaRPackg::get_gar_forecast(partitions_list = temp_part,
                                vars_df = temp_df,
                                transform_vars_df = FALSE,
                                target_var_name = "gdp_yoy",
                                horizon_list = c(1,4,8,12),
                                quantile_vec = c(0.1,0.25,0.5,0.75,0.95))
  
  

  
}

parallel::stopCluster(cl)

names(forecast_results) = as.character(start_ind:end_ind)


```


```{r check_forecast, eval=FALSE}

temp_forecast = forecast_results[[3333]]

target_part = feature_select_df$partition[[3333]]

target_forecast = get_gar_forecast(partitions_list = target_part,
                                vars_df = raw_df,
                                target_var_name = "gdp_yoy",
                                horizon_list = c(1,4,8,12),
                                quantile_vec = c(0.1,0.25,0.5,0.75,0.95))

all.equal(temp_forecast, target_forecast)

```

## Import forecast and calculate scores

```{r calculate_scores_and_save}

benchmark_df = get_gar_forecast(partitions_list = NULL,
                                vars_df = raw_df,
                                target_var_name = "gdp_yoy",
                                horizon_list = c(1,4,8,12),
                                quantile_vec = c(0.1,0.25,0.5,0.75,0.95))

actual_df = transformed_df %>% 
  select(date, gdp_yoy)


scores_df = map_dfr(forecast_results, function(temp_forecast_df){
  
  temp_r2 = quantile_r2_score(forecast_df = temp_forecast_df,
                              actual_df = actual_df,
                              benchmark_df = benchmark_df)
  
  return(temp_r2)
  
  
},
.id = "row")


```


```{r plot_scores}

scores_df %>% 
  ggplot(aes(x = quantile_r2)) + 
  geom_histogram() + 
  geom_vline(xintercept = 0, color = "blue", linetype = "dashed") + 
  facet_grid(vars(horizon), vars(quantile), scales = "free")

```


```{r select_best_models}


best_thresholds = scores_df %>%
  group_by(horizon, quantile) %>%
  summarise(threshold_r2 = quantile(quantile_r2, 0.55), .groups = "drop")


best_models = scores_df %>%
  left_join(best_thresholds, by = c("horizon","quantile")) %>%
  filter(quantile_r2 >= threshold_r2) %>%
  group_by(row) %>%
  mutate(obs = length(quantile_r2)) %>%
  ungroup() %>%
  filter(obs == 20)


best_partitions = feature_select_df %>% 
  select(partition) %>% 
  slice(best_models %>% 
          select(row) %>% 
          distinct() %>% 
          pull() %>% 
          as.numeric())

map(best_partitions$partition, ~unlist(.,use.names = FALSE))

```

```{r plot_best_models} 

best_models %>% 
  ggplot(aes(quantile, quantile_r2)) + 
  geom_col(aes(fill = row),position = "dodge", show.legend = FALSE) + 
  facet_wrap(~horizon, scales = "free")

```

